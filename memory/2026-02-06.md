# 2026-02-06 工作日志

## 高校数字资产管理系统 - P2 任务完成

### 完成的功能

#### F-015 下载记录
- 创建 `DownloadRecord` 模型
- 下载接口自动记录：user_id, document_id, ip_address, user_agent
- API: `/logs/downloads` (管理员), `/logs/my-downloads` (用户)

#### F-016 操作日志
- 创建 `OperationLog` 模型
- 登录自动记录操作日志
- API: `/logs/operations` (管理员)

#### 用户管理页面完善
- 用户列表（筛选、分页）
- 新增/编辑用户
- 重置密码（默认123456）
- 批量导入（JSON/CSV）

### Bug 修复
- **UUID 验证**: 添加 `_parse_uuid()` 辅助函数，无效 UUID 返回 400 而不是 500 错误

### 新增文件
- `backend/app/models/download_record.py`
- `backend/app/models/operation_log.py`
- `backend/app/services/log_service.py`
- `backend/app/api/v1/logs.py`

### 数据库表
```sql
CREATE TABLE download_records (...)
CREATE TABLE operation_logs (...)
```

### Git 提交
- `ba4d67a` feat: 下载记录和操作日志 (F-015/F-016)

### 部署状态
- 后端: ✅ 运行中 (port 8000)
- 前端: ✅ 已更新
- 访问: https://gxzc.chuhaibox.com

### 项目完成度
- Phase 1: 100%
- Phase 2: 100%
- Phase 3: 100%
- **所有 P0/P1/P2 功能完成！**

### 剩余工作 (Phase 4)
- F-050/F-051 性能优化 & 安全加固
- F-054 文档完善

---

## 智能检索功能修复 (15:00-16:00)

### 问题诊断
1. **向量数据为空** - Milvus Entities: 0
2. **文档未处理** - 所有文档 `process_status = pending`
3. **自动处理任务失败** - 上传后异步处理未执行

### 修复措施
1. 创建手动处理脚本 `scripts/process_pending.py`
2. 执行文档向量化处理
3. 结果：
   - 2/4 文档成功处理
   - 2/4 失败（测试用无效文件）
   - Milvus 现有 **16 个向量**

### 测试验证
```
搜索: "逃荒"
结果: 10 条
耗时: 43秒 (首次加载模型)
✅ 智能检索已恢复正常
```

### LLM 配置问题
- **当前配置**: yunyi.cfd/codex 代理
- **支持模型**: gpt-5.1, gpt-5.3-codex (非标准)
- **状态**: ❌ API 调用失败，代理不稳定
- **AI 摘要**: 失败时降级为文本截取

### 智能检索逻辑
```
用户查询 → Embedding (384维) → Milvus 向量搜索 → 文档聚合 → 返回结果
```

---

## LLM 修复完成 (17:00-18:00)

### 问题
- Codex API (yunyi.cfd/codex) 使用 **OpenAI Responses API** 格式
- 必须设置 `stream: true`，否则返回 500 错误
- 旧代码使用标准 Chat Completions API，不兼容

### 解决方案
重写 `app/services/llm.py`：
1. 新增 Codex provider (优先级最高)
2. 支持 Responses API (`/codex/responses` endpoint)
3. 流式读取 + 解析 SSE 格式
4. 提取 `response.output_text` 字段

### 配置 (.env)
```
CODEX_API_KEY=61T1F0XG-7VHF-ZPP9-JKN6-A1F5YF14GXQX
CODEX_API_BASE=https://yunyi.cfd/codex
LLM_MODEL=gpt-5.3-codex
```

### 测试结果
```
AI摘要生成: ✅ 成功
文档: 带着随身超市在古代逃荒
内容: 描述故事讲述了从农村搬到城市的女孩杨灵珊的故事...
```

---

## 高级检索系统升级 (18:00-20:00) ⭐

### 老大需求
"做最牛的事情" - 实现业界领先的混合检索架构

### 新增服务
1. **Reranker Service** (`reranker.py`)
   - 模型: BAAI/bge-reranker-base
   - Cross-Encoder 精排

2. **BM25 Service** (`bm25.py`)
   - Okapi BM25 算法
   - jieba 中文分词
   - 414 词汇量

3. **Hybrid Search Service** (`hybrid_search.py`)
   - Vector + BM25 双路召回
   - RRF (Reciprocal Rank Fusion) 融合
   - 权重: 向量 0.5 + BM25 0.5

### 搜索模式
| Mode | 说明 | 用途 |
|------|------|------|
| keyword | 纯关键词 | 精确匹配 |
| vector | 纯向量 | 语义理解 |
| hybrid | 混合召回 | 平衡 |
| smart | 混合+重排 ⭐ | 最佳效果 |

### 架构图
```
查询 → [Vector Search] + [BM25 Search]
              ↓
         RRF Fusion
              ↓
        BGE Reranker (精排)
              ↓
         返回结果
```

### 性能测试
| 场景 | 时间 |
|------|------|
| 首次搜索 (加载模型) | ~135秒 |
| 后续搜索 (模型缓存) | **~4秒** ⚡ |

### 测试结果
```
Query: "游戏设定规则"
Mode: smart
Time: 4092ms
Results: 2
Rerank Score: 0.3672
```

### 部署状态
- ✅ 后端已部署 (8.140.214.182)
- ✅ BM25 索引已构建
- ✅ Embedding 模型加载
- ✅ Reranker 模型加载

### Git 提交
- 待提交: feat: 高级混合检索系统 (BM25 + Reranker + RRF)

---

## 今日总结

### 完成
1. ✅ 下载记录 + 操作日志 (F-015/F-016)
2. ✅ 智能检索修复 (向量化处理)
3. ✅ LLM 配置修复 (Codex Responses API)
4. ✅ **高级检索系统** (BM25 + Reranker + RRF)

### 技术栈
- Embedding: paraphrase-multilingual-MiniLM-L12-v2 (384维)
- Reranker: BAAI/bge-reranker-base
- BM25: jieba 分词 + Okapi BM25
- Fusion: RRF (k=60)

### 项目状态
高校数字资产管理系统现在拥有**业界领先的混合检索架构**！

---

## 文档自动处理 + 通知系统 (19:50-20:00)

### 问题诊断
文档上传后停留在 `pending` 状态，不自动向量化

**根本原因**: 后台任务使用了已关闭的数据库会话
```python
# 问题代码
asyncio.create_task(process_in_background())  # 复用 request 的 db session
```

### 修复措施
1. **创建独立数据库会话**
   ```python
   async with async_session_maker() as bg_db:
       await document_processing_service.process_document(doc_id, bg_db)
   ```

2. **添加处理完成通知**
   - 成功: `✅ 文档处理完成，可以通过智能搜索找到了`
   - 失败: `❌ 文档处理失败，请联系管理员`
   - 通知出现在右上角铃铛

### 修改文件
- `backend/app/api/v1/documents.py` - 后台任务使用独立 session

---

## RAG 对话功能 (20:43-21:00) ⭐

### 老大需求
"对话的模块，要可以基于当前对话的内容继续对话"

### 实现方案
新增 `POST /api/v1/chat/ask` 接口

**请求**:
```json
{
  "question": "问题",
  "session_id": "可选，传入则继续对话"
}
```

**响应**:
```json
{
  "answer": "AI 回答",
  "session_id": "会话ID",
  "sources": [...],
  "search_time_ms": 5000
}
```

### 功能特点
| 功能 | 状态 |
|------|------|
| 首次对话自动创建会话 | ✅ |
| 继续对话加载历史上下文 | ✅ |
| 混合检索 + 重排 | ✅ |
| 显示引用来源 | ✅ |
| 自动保存对话记录 | ✅ |

### 测试验证 (三轮对话)
```
第一轮: "简历里提到了哪些技术栈？"
→ Java、Spring Boot、MySQL、Redis...

第二轮: "他做过什么项目？" (理解"他"指简历主人)
→ 上贤软件实训、蓝桥杯、Jenkins+GitLab 部署

第三轮: "帮我整理一下他的联系方式"
→ 电话: 18350958922 ✅
```

### 技术实现
1. 检索相关文档（hybrid + rerank）
2. 加载历史对话（最近 6 条）
3. 调用 LLM 生成回答
4. 保存对话记录到数据库

### 修改文件
- `backend/app/api/v1/chat.py` - 新增 `/ask` 接口

### 下一步
- 前端对话界面对接此接口

---

## Cron 错误记录
```
Error: Unknown model: google-antigravity/claude-opus-4-6-thinking
```
每日检查 Opus 4.6 的 cron job 失败，因为模型不存在
